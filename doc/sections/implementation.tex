
\chapter{Implementierung}
\label{impl}

In diesem Kapitel wird auf Besonderheiten und Schwierigkeiten bei der Implementierung des Systems eingegangen.
Optionale Anforderungen, die umgesetzt wurden, werden zudem erwähnt und die Umsetzung erklärt.


%Weitestgehend wie in \autoref{draft:architecture}, aber Futures, tokio, Queues

\section{Continuous Integration mittels Jenkins}

Um die nichtfunktionalen Anforderungen zur Qualität umsetzen zu können (Anforderung \reqNumberForLabel{quality:ci}, siehe \autoref{req:quality:ci}), wird die Continuous Integration Software Jenkins genutzt.
Nach jeder Aktualisierung des Quellcode-Repository wird eine neuer Compileversuch gestartet.
In einem Jenkins-File ist hierzu die folgende Pipeline definiert:

\begin{figure}[H]
	\includegraphics[width=\textwidth]{images/jenkins_pipeline_graph.png}
	\caption{Jenkins Pipeline Graph}
	\label{impl:jenkins:pipeline:graph}
\end{figure}

Im Folgenden sind die einzelnen Schritte genauer erklärt.


\subsubsection{Schritt \enquote{prepare}}
In diesem Schritt wird überprüft, ob die richtige Version von Rust installiert ist.
Sowohl der Rust Compiler als auch Abhängigkeiten wie Cargo, Clippy oder Tarpaulin werden falls nötig  in diesem Schritt nachinstalliert und aktualisiert.

\subsubsection{Schritt \enquote{check-src}}
%\todo{\reqNumberForLabel{nfktl:styleguide} \reqNameForLabel{nfktl:styleguide}} \\
Hier wird der Quellcode auf einen schlechten Programmierstil oder schlechte Programmierpraktiken durch Clippy und auf eine nicht standardkonforme Formatierung überprüft (Anforderung \reqNumberForLabel{nfktl:styleguide}, siehe \autoref{req:nfktl:styleguide}).
Ein erkannter Mangel resultiert in einem Abbruch und entsprechendem roten Icon auf der Projektseite auf Jenkins.
Ein Quellcode, der diese Qualitätsstandards nicht erfüllt, wird somit schnellstmöglich abgelehnt.

\subsubsection{Schritt \enquote{Build-Debug}}
In diesem Schritt wird das Projekt im Debug-Modus compiliert.
In einem Debug-Modus werden nahezu keine Optimierungen durchgeführt, weswegen die Ausführgeschwindigkeit meist mangelhaft ist.
Im Falle eines Fehlers in einem Unit-Test, können aus einem Debug-Artefakt jedoch nützlich Informationen gewonnen werden.

\subsubsection{Schritt \enquote{Build-Release-And-Test-Debug}}
Wie der Name bereits vermuten lässt, wird in diesem Schritt das Projekt im Release-Modus übersetzt.
%\todo{\reqNumberForLabel{quality:ci:test} \reqNameForLabel{quality:ci:test}} \\
Gleichzeitig wird das zuvor erstellte Debug-Artefakt auf Fehler überprüft, indem Unit-Tests ausgeführt werden (Anforderung \reqNumberForLabel{quality:ci:test}, siehe \autoref{req:quality:ci:test}).
Ein Release-Artefakt ist stark optimiert und ist für den Produktivbetrieb geeignet.

\subsubsection{Schritt \enquote{Test-Release}}

In diesem Schritt wird das Release-Artefakt mittels Unit-Tests auf Fehler überprüft.
Hierdurch soll sichergestellt werden, dass kein Fehler durch Optimierungen des Compilers aufgedeckt oder verursacht wurde.
Des weiteren soll kein Artefakt archiviert werden, das nicht auf Fehler überprüft wurde.

\subsubsection{Schritt \enquote{Post-Build}}
Dieser Schritt dient zur Zusammenstellung der Testabdeckung der Unit-Tests und der automatisierten  Erstellung der Dokumentation.

\subsubsection{Ergebnis des erfolgreichen Durchlaufs}
%\todo{\reqNumberForLabel{quality:ci:artefacts} \reqNameForLabel{quality:ci:artefacts}} \\
Jede Aktualisierung des Quellcode-Repository resultiert bei erfolgreicher Compilation und Durchlaufen der Tests in den folgenden Artefakten (Anforderung \reqNumberForLabel{quality:ci:artefacts}, siehe \autoref{req:quality:ci:artefacts}):
\begin{itemize}
	\item \textbf{Debug-Artefakt}: Compilation für eine manuelle Fehlersuche mit vielen auf den Quellcode bezogenen Symbolen und ohne Optimierungen durch den Compiler.
	\item \textbf{Release-Artefakt}: Kompilat mit Optimierungen für den Produktivbetrieb.
	\item \textbf{Testbericht}: Bericht über wie viele Zeilen, Dateien, Klassen und Verzweigungen durch die Unit-Tests getestet wurden.
	\item \textbf{Dokumentation}: Die aus dem Quellcode generierte Dokumentation inklusive der Dokumentationen der Abhängigkeiten.
\end{itemize}

Für jeden erfolgreichen Bauvorgang, werden die erhobenen Informationen in die folgenden Graphen auf der Projektseite auf Jenkins übernommen:

\begin{figure}[H]
	\centering
	\begin{subfigure}{.5\textwidth}
		\includegraphics[width=\textwidth]{images/jenkins_coverage_graph.png}
		\caption{Jenkins Coverage Graph}
		\label{impl:jenkins:coverage:graph}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\includegraphics[width=\textwidth]{images/jenkins_warnings_graph.png}
		\caption{Jenkins Warnings Graph}
		\label{impl:jenkins:warnings:graph}
	\end{subfigure}
\end{figure}

\autoref{impl:jenkins:coverage:graph} zeigt die Testabdeckung seit Aufzeichnungsbeginn.
Die frühen und starken Schwankungen resultieren aus Testdurchläufen bei der Einrichtung des Graphen.
\autoref{impl:jenkins:warnings:graph} zeigt Warnungen, die der Rust Compiler für die verschiedenen Builds ausgegeben hat.

Die Graphen starten bei unterschiedlichen Versionen, da sie nacheinander eingerichtet wurden.

\clearpage
\section{Asynchrone Kommunikation}
\label{impl:channels}

Wie bereits in \autoref{design:communication:architecture:async} festgestellt, ist für eine hochperformante Kommunikationsplattform eine interne Parallelisierung fördernd.
Die Kommunikation von den zueinander asynchron arbeitenden Klassen kann mit Hilfe von verschiedenen Entwurfsmuster umgesetzt werden.

Das \enquote{Message Queuing Pattern} (dt. Nachrichten-Warteschlange-Muster) gilt als stabiles und einfach umzusetzendes Entwurfsmuster, um zwischen asynchron arbeitenden Klassen Nachrichten auszutauschen \cite[207]{douglass2003real}.
Der im Jahre 2003 von E. Douglas Jensen genannte Nachteil, Werte nur \enquote{by-value} austauschen zu können \cite[211]{douglass2003real}, ist seit der Verfügbarkeit des \ccinline{std::shared_ptr} ab C++11 nicht mehr relevant.
Auch in Rust ist diese Einschränkung durch das Eigentümerprinzip und der Hilfsklassen \rustcinline{Arc}  nicht gegeben.
%Es gilt allerdings als schwergewichtig, da im klassischen Sinne nur Werte \enquote{by-value} ausgetauscht werden können sollen.
%Bei Austausch von Werten \enquote{by-reference} ist das Ressourcenmanagement deutlich komplizierter und Speicherlecks oder \enquote{double-free}s könnten auftreten\footnote{Helfer, wie \ccinline{std::shared_ptr} aus C++11, sind zum Zeitpunkt der }. 
%Aufgrund des Eigentümerprinzips in Rust können Nachrichten jedoch auch sicher \enquote{by-reference} (\todo{owning reference Box}) ausgetauscht werden.
Das \enquote{Message Queuing Pattern} soll daher für die interne Kommunikation zwischen \textit{Algorithm} und \textit{Client} bzw. zwischen \textit{Algorithm} und \textit{Sensor} und \textit{Vehicle} verwendet werden

\subsubsection{Nachrichtenkanäle}

Mittels \enquote{channels} (dt. \enquote{Kanäle}) können in Rust Mitteilungen zwischen vielen Auftraggebern und einem Empfänger ausgetauscht werden (andere Rust-Bibliotheken erlauben auch viele Empfänger, zum Beispiel \enquote{crossbeam-channel}\footnote{\url{https://crates.io/crates/crossbeam-channel}}).
Der zu versendende Datentyp muss lediglich das Merkmal \rustcinline{Send} aufweisen (siehe \autoref{rust:trait:send}):

\rustcinclude
	{impl:channels:example}
	{Beispiel für die Nutzung von Kanälen}
	{sections/impl.channels.rs}

\autoref{impl:channels:example} zeigt ein einfaches Beispiel, wie ein asynchroner  und sicherer Nachrichtenaustausch in Rust umgesetzt werden kann.
Zur Laufzeit gibt das Beispielprogramm \monospaceinline{Empfangen: Hallo, Kanal!} auf der Konsole aus.

In Zeile 5 wird ein neuer Kanal erzeugt und ein Sende- und ein Empfängerteil zurückgegeben.
Zwischen Zeile 7 und 9 wird ein neuer Thread erzeugt und der auszuführenden Closure (siehe \autoref{rust:closures}) die Eigentümerschaft über den Empfänger übertragen (Schlüsselwort \rustcinline{move}).
Der neue Thread wartet nach Start auf den Empfang einer neuen Nachricht und gibt diese anschließend auf der Konsole aus.
In Zeile 11 sendet der Haupt-Thread über den Kanal dem anderen Thread einen Text\footnote{Um genau zu sein, ist der Wert vom Datentyp \rustcinline{&`static str} } zu und wartet in Zeile 12, bis dieser beendet wurde.

Um nicht für jeden Datentyp einen neuen Kanal erstellen zu müssen, kann das \enquote{Command Pattern} (dt. Kommando Verhaltensmuster) \cite[153]{goll2014architektur} verwendet werden, um über einen Kanal mehrere Aktionen zu befehligen.
In Rust kann dies mit einem \rustcinline{enum} umgesetzt werden:

\rustcinclude
	{impl:commands:example}
	{Beispiel für die Nutzung von Kanälen und des Kommando-Verhaltensmusters}
	{sections/impl.commands.rs}
	
In \autoref{impl:commands:example} ist die Aktion, Etwas auf der Konsole auszugeben, als Variante \rustcinline{Say} in dem Kommando definiert.
Für eine Instanz dieser Variante wird zudem ein \rustcinline{String} verlangt, der daraufhin innerhalb von \rustcinline{execute} in Zeile 11 ausgegeben wird.

Nach diesem Beispiel ist die Kommunikation zwischen dem \textit{Algorithm}, dem \textit{Client}, dem \textit{Vehicle} und dem \textit{Sensor} in der tatsächlichen Implementation realisiert (siehe \autoref{draft:architecture}).
In dem folgenden \autoref{impl:commands:algorithm} sind die Befehle zu sehen, die in der tatsächlichen Implementation an den Algorithmus versendet werden können.

\rustcinclude
	{impl:commands:algorithm}
	{Kommandos, die einem \textit{Algorithm} zugesandt werden können}
	{sections/impl.command.algorithm.rs}

Ob eine Kommunikation zwischen zwei Klassen asynchron oder synchron stattfindet, sollte für die Implementation jedoch möglichst keine Rolle spielen.
Zur Kommunikation mit anderen Klassen sollte es nur nötig sein, die entsprechende Schnittstelle zu kennen (Stichwort \enquote{loose coupling} \cite[49]{goll2018entwurfsprinzipien}).
Die verwendete Kommunikationstechnologie (\textit{Tokio}) und das Verhaltensmuster (Kommando) beziehen sich nicht mehr auf das Aufgabengebiet der Klassen.
Durch eine Fassade kann das Erstellen eines Kommandos und das Übermitteln durch einen Kanal gekapselt und auf einen einfachen Methodenaufruf reduziert werden.
Durch eine Implementation der Schnittstelle für den Sendeteil kann aber auch das \enquote{Proxy Pattern} (dt. Stellvertreter-Strukturmuster) \cite[137]{goll2018entwurfsprinzipien} umgesetzt werden, wodurch keine Änderung in der aufrufenden Klasse bemerkbar ist.
%Die Verwirklichung mittels Schnittstellen und einer Methode für jedes Kommando entspricht letztendlich dem \enquote{Proxy Pattern} (dt. Stellvertreter-Strukturmuster) \cite[137]{goll2018entwurfsprinzipien}.

Da ein Beispiel aus der tatsächlich Implementierung zu groß für eine übersichtliche Erläuterung ist, wird das Beispiel aus \autoref{impl:channels:example} und \autoref{impl:commands:example} erneut aufgegriffen, um beispielhaft das Prinzip zu erklären.

Die neue Schnittstelle \rustcinline{EndPoint} definiert die Funktion \rustcinline{say}, um einen Text auf der Konsole auszugeben.
Anschließend wird sie für den Sendeteil des Kanals implementiert, wodurch dieser quakt\footnote{\enquote{Duck Typing} \cite[44]{rust:orly_programming} in Rust teilweise möglich, dann aber ohne Laufzeitkosten. Auch genannt Ententest: \enquote{When I see a bird that walks like a duck and swims like a duck and quacks like a duck, I call that bird a duck.} von James Whitcomb Riley \cite{wiki:duck}} wie die \rustcinline{EndPoint}-Schnittstelle.
Für Zeile 35 ist daher nicht erkenntlich, dass es sich um einen Kanal handelt.

Auf der Konsole wird \monospaceinline{Say: Hallo, Proxy!} ausgegeben.

\rustcinclude
	{impl:commands:facade}
	{Command und Proxy Pattern}
	{sections/impl.commands.facade.rs}

In der tatsächlichen Implementierung wird innerhalb der \rustcinline{execute} Methode von \rustcinline{Command} eine entsprechende Methode in \textit{Client} oder \textit{Algorithm} aufgerufen.

Als weitere Leistungsoptimierung sind die Kommunikationspartner, wie der \textit{Algorithm} für den \textit{Client}, mittels generische Typen eingebettet (siehe \autoref{rust:generics}).
Dem Compiler ist hierdurch bekannt, welche Datentypen sich tatsächlich hinter den generischen Typen (\rustcinline{D} und \rustcinline{A} in \autoref{impl:commands:fast_generic}) verbergen und kann den Maschinencode trotz Abstraktion ungehindert optimieren\footnote{\enquote{Despite their flexibility, generic functions [and structs] are just as efficient as their nongeneric counterparts.}\cite[45]{rust:orly_programming}}.

\rustcinclude
	{impl:commands:fast_generic}
	{Ausschnitt aus der Datenstruktur \textit{Client} zeigt generische Typen für \textit{Algorithm} und \textit{Adapter}}
	{sections/impl.command.client.rs}
	
Ein \enquote{Trait-Object} (siehe \autoref{impl:commands:fast_generic}), wie etwa \rustcinline{Box<Adapter>}, würde dagegen einen \enquote{vtable} Zugriff zur Laufzeit erzwingen und eine Optimierung für den konkreten Datentyp unterbinden, da dieser meist nicht zur Compilezeit bekannt oder eindeutig ist.

\clearpage
\section{ASN.1 via Bindgen einbinden}
\label{impl:asn1_bindings}
\label{impl:issue:ffi}


Wie bereits in \autoref{draft:no_asn_compiler} geschildert, existiert für Rust zum jetzigen Zeitpunkt kein ASN.1 Compiler, der die Nachrichtendefinition in nativen Rust-Code übersetzt.
Aus diesem Grund müssen die selben C-Datenstrukturen und C-Funktionen genutzt werden, die auch die C++ Referenzimplementation nutzt.
Mittels \gls{ffi} (siehe \autoref{rust:ffi}) wird auf diese zugegriffen.
Damit nicht für jeden Nachrichtentyp, eingebetteten Nachrichtenuntertyp und jede Funktion manuell eine Rust Deklaration geschrieben werden muss, wird Bindgen\footnote{\url{https://crates.io/crates/bindgen}} genutzt, um diese automatisch zu generieren.

%\todo{komplizierter Satz}
Um wichtige Nachrichtentypen ohne \rustcinline{unsafe}-Blöcke instantiieren zu können, ist der unsicher Code in \rustcinline{Default} gekapselt worden.
Für eine korrekte Deallocation des Nachrichtenrumpfes wurde bei diesen Nachrichtentypen zudem \rustcinline{Drop} %(das Rust Äquivalent zu C++ Destruktoren, siehe \autoref{rust:drop})
implementiert.
% und für eine korrekte Deallocation, sind hierfür die Rust Äquivalente von Konstruktoren und Destruktoren implementiert worden.
Als Beispiel dient die \textit{ClientRegistration}-Nachricht in \autoref{impl:bindings:constructor:clientregistration}:


\rustcinclude
	{impl:bindings:constructor:clientregistration}
	{Auszug aus \textit{lib.rs} der \textit{libmessages-sys} Crate}
	{sections/impl.constructor.destructor.rs}
	
Die \textit{ClientRegistration}-Nachricht aus \autoref{impl:bindings:constructor:clientregistration} wird selbst im Speicherbereich von Rust allokiert, während der Inhalt der Nachricht auf dem C-Heap erwartet wird.
Dieser Mix ist nicht zu vermeiden, da die ASN.1 Funktionen zum Dekodieren der UPER-Nachrichten die inneren Datenstrukturen auf dem C-Heap anlegen.
Dieser Mix ist nicht zu vermeiden, da die ASN.1 Funktionen zum Dekodieren der UPER-Nachrichten die inneren Datenstrukturen auf dem C-Heap anlegen, während eine Deallokation einer Heap-Variable in Rust (\rustcinline{Box}) nicht ohne erheblichen Aufwand\footnote{Die Deallokation müsste \textbf{manuell} und durch Nutzung von unsicherem Code erfolgen, ohne ein Hilfe durch den Compiler, ob dies immer an jeder Stelle umgesetzt wurde.} beeinflusst werden kann.
%Würde sich die \textit{ClientRegistration}-Nachricht auch auf dem C-Heap befinden, müsste entweder ein Zugriff mittels \enquote{Raw-Pointer} (siehe \autoref{rust:ffi}) erfolgen oder die automatische Deallocation von Rust müsste verhindert werden.
%Die Deallocation von Rust würde bei einem vergessenen manuelle Eingriff den C-Heap korrumpieren.
%Beide Szenarien würden Konzepte der Speichersicherheit von Rust untergraben.

Die Deklarationen, zusammen mit einer statischen Linkung mit der C-Bibliothek, ist in der \textit{libmessages-sys} umgesetzt und entspricht damit der Rust-Konvention beim Einbinden externer Bibliotheken\cite{rust:cargo:build_scripts}.
Durch die Kapselung möglichst aller \rustcinline{unsafe} Operationen in \textit{libmessages-sys} wird eine sicherer Nutzung außerhalb dieser Crate ermöglicht.
Das Prinzip, unsichere Code in sichere Funktionen oder Abstraktionen zu kapseln, entspricht auch der Rust-Konvention zur Einbindung externer Bibliotheken\footnote{\enquote{Creating a Safe Abstraction Over Unsafe Code}}\cite{rust:book:unsafe}.



\subsubsection{Schwierigkeiten}

Bei ersten Tests wurde schnell festgestellt, dass der Speicher, der durch C-Funktionen allokiert wurde, von C-Funktionen wieder freigegeben werden muss\footnote{Kommentar: Das klingt im Nachhinein leider offensichtlicher als es ist.}.
Falls innerhalb der C-Nachrichtentypen Rust-Heap referenziert, oder die C-Nachrichtentypen von Rust Funktionen freigegeben werden, wird der jeweilige Heap korrumpiert.
Ein späterer Versuch Speicher zu allokieren endet in einem Deadlock-ähnlichen Zustand, bei dem der Allokator stehen bleibt.

%\todo{Image}


\clearpage
\section{C++ Algorithmus laden}

Um die optionale Anforderung \reqNumberForLabel{possible:external_algorithm} (\enquote{\reqNameForLabel{possible:external_algorithm}}, siehe \autoref{req:possible:external_algorithm}) umsetzen zu können, muss zuerst die Kommunikation innerhalb des C++ Servers mit dessen Algorithmus analysiert werden:

\begin{figure}[H]
	\begin{tikzpicture}[scale=0.9]
	\begin{umlseqdiag} 
	\umlobject[x=-7,no ddots]{MEC-View-Server}
	\umlobject[x=4,no ddots]{AlgorithmFactory}
%	\umlobject[x=12,class=Algorithm]{a}

	\umlcreatecall[dt=7,class=QueueListener<SensorFrame\_t>,x=-2]{MEC-View-Server}{q}
	\umlcreatecall[dt=5,class=EnvironmentListener,x=2]{MEC-View-Server}{e}
	
	
	\begin{umlcall}[dt=7, op={<<static>> Create(e, q, config\_file)},return=a]{MEC-View-Server}{AlgorithmFactory}
		\umlcreatecall[class=Extension,x=8]{AlgorithmFactory}{a}
	\end{umlcall}
	
	%\begin{umlcall}[op={Start()}]{AlgorithmFactory}{a}
		
	\begin{umlfragment}[type=loop]
	
		\begin{umlcall}[dt=7, type=synchron, op={Add(sensor\_frame)},with return]{MEC-View-Server}{q}
		\end{umlcall}
		
		\begin{umlcall}[dt=18, op={Pop()},return=sensor\_frame]{a}{q}
		\end{umlcall}
		%\begin{umlcall}[dt=7, op={Update(sensor\_frame)}]{a}{a}
		%\end{umlcall}
		\begin{umlcall}[dt=7, op={Update(env\_frame)}]{a}{e}
		\end{umlcall}
		
	\end{umlfragment}
	%\end{umlcall}
	
	\umlsdnode[dt=20]{MEC-View-Server}
	\umlsdnode[dt=13]{q}
	\umlsdnode[dt=4]{e}
	\umlsdnode[dt=29]{AlgorithmFactory}
	\umlsdnode[dt=4]{a}
	
	
	\end{umlseqdiag}
	\end{tikzpicture}
	\centering
	\caption{Instantiierung eines neuen Algorithmus in der C++ Implementation}
	\label{seq_dia:algorithm:cpp}
\end{figure}

In \autoref{seq_dia:algorithm:cpp} ist sowohl die Instantiierung des Algorithmus (Klasse \textit{Extension}) als auch Übermittlung von \textit{SensorFrame}- und \textit{EnvironmentFrame}-Nachrichten (siehe \autoref{msg:sensor_frame} und \autoref{msg:environment_frame}) zu sehen.
Die Kommunikation zwischen dem Algorithmus und der Außenwelt findet über den \textit{QueueListener} und den \textit{EnvironmentListener} statt.
Neue \textit{SensorFrame}-Nachrichten werden in den \textit{QueueListener} eingefügt und zu einem späteren Zeitpunkt asynchron vom Algorithmus ausgelesen.
Eine neue \textit{EnvironmentFrame}-Nachricht übergibt der Algorithmus an den \textit{EnvironmentListener}.
Über diesen wird in der C++ Implementation anschließend die Nachricht an alle Fahrzeuge verteilt.

Die C++ Implementation reduziert durch dieses Vorgehen die direkte Kommunikation zwischen dem Server und dem konkreten Algorithmus auf den Aufruf von \textit{Create}.
Durch den Austausch dieser Methode kann ein anderer Algorithmus geladen werden.

Damit die Rust-Implementation den C++ Algorithmus instantiieren kann, muss die Methode \textit{Create} der Klasse \textit{AlgorithmFactory} ordnungsgemäß aufgerufen werden.
Ein gültiger \textit{QueueListener} und \textit{EnvironmentListener} muss zuvor erstellt werden.
Der Fokus liegt somit auf den folgenden Klassen:

\begin{figure}[H]
	\begin{tikzpicture}[scale=0.8, every node/.style={transform shape}]
		\umlclass[x=-11.0,y=-9.5]{mec::algorithm::AlgorithmFactory}{}{
			+ Create(\\
			\quad{}std::weak\_ptr<mec::environment::EnvironmentListener>,\\
			\quad{}std::weak\_ptr<mec::environment::QueueListener<SensorFrame\_t>>,\\
			\quad{}config\_file: std::string\\
			): std::shared\_ptr<mec::extension::Extension>
		}
		
		\umlclass[x=-6.0,y=-5,type=interface]{mec::environment::EnvironmentListener}{}{
			+ Update(frame: std::shared\_ptr<EnvironmentFrame\_t>) \\
			+ Init(init\_message: std::shared\_ptr<InitMessage\_t>) \\
		}
		
		\umlsimpleclass[y=-9.5,type=interface]{mec::extension::Extension}
		
		
		\umlclass[x=-6.0,y=-15,type=interface,template=T]{mec::environment::QueueListener}{}{
			+ Add(sensor\_frame: const std::shared\_ptr<T>): void \\
			+ Pop(): const std::shared\_ptr<T> \\
			+ Pop(timeout: std::chrono::duration<int, std::milli>): const std::shared\_ptr<T> \\
			+ MessageAvailable(): bool \\
			+ GetMessageCount(): int \\
			+ SetStop(stop: bool) \\
		}
		
		\umluniassoc{mec::extension::Extension}{mec::environment::QueueListener}
		\umluniassoc{mec::extension::Extension}{mec::environment::EnvironmentListener}
		\umluniassoc{mec::algorithm::AlgorithmFactory}{mec::extension::Extension}
	\end{tikzpicture}
	\centering
	\caption{Abhängigkeiten zum Instantiieren des C++ Algorithmus}
	\label{class_dia:algorithm:cpp}
\end{figure}

Der C++ Algorithmus soll durch einen Adapter dem Merkmal des Rust \textit{Algorithm} entsprechen, um eine Änderung im bestehenden Rust Code möglichst gering zu halten.
Eine Änderung im C++ Quellcode des Algorithmus ist untersagt.

Im ersten Schritt wird der Methodenaufruf von \textit{AlgorithmFactory::Create} in Rust zugänglich gemacht.
Anschließend wird der nötige Adaptercode implementiert.
Wegen der wachsenden Komplexität wird auch die Architektur erweitert und, aufgrund der nun höheren Anzahl an Klassen, in weitere Crates aufgeteilt.
In \autoref{draft:architecture} ist die erweiterte Version zu sehen.

\begin{figure}[H]
	\centering
	\includegraphics[width=3.3\textwidth]{dia/architecture_v2}
	\caption{Architekturentwurf}
	\label{draft:architecture_v2}
\end{figure}

Die \textit{Algorithm}-, \textit{CountListener}- und \textit{EnvironmentListener}-Schnittstellen werden in eigene Crates verschoben.
Die \textit{asn::Message} wird in \textit{AsnMessage} umbenannt und zusammen mit der \textit{AsnAdapter}-Klasse in die neue Crate \textit{libasn} verschoben.
Auch der \textit{SampleAlgorithm} wird in eine eigene Crate verschoben.
Zwei weiteren Crates binden den externen C++ Algorithmus ein: \textit{libshim-sys} um den C++ Code in Rust zugänglich zu machen (analog zu \textit{libasn-sys}) und \textit{libshim} für die Implementation der \textit{Algorithm}-Schnittstelle mittels Adaptercodes.

Die neuen Abhängigkeiten zwischen den Crates sind in \autoref{draft:architecture_v2_packages} abgebildet.

\begin{figure}[H]
	\centering
	\includegraphics[width=1.9\textwidth]{dia/architecture_v2_packages}
	\caption{Architekturentwurf}
	\label{draft:architecture_v2_packages}
\end{figure}

Die roten Abhängigkeiten entstehen erst durch die Wahl einer Nachrichtentechnologie und des auszuführenden Algorithmus, und können durch die Instantiierung einer anderen Implementation in der \textit{main}-Funktion der \textit{MECViewServer}-Crate ausgetauscht werden.


Die Einbindung des C++ Quellcodes ist im Gegensatz zum C-Code der ASN.1 Nachrichten (siehe \autoref{impl:asn1_bindings}) deutlich schwieriger.
Die Abhängigkeiten zu den Datentypen der Standardbibliothek (siehe \autoref{class_dia:algorithm:cpp}) und die Klassenhierarchie macht einen Zugriff aus Rust deutlich komplizierter und würde eine manuelle Pflege der \textit{vtable} benötigen.
Deswegen ist eine andere Herangehensweise ausgewählt worden.
Weiterer C-Code soll den C++ Code über eine C-Datenstruktur kapseln und über C-Funktionen zugänglich machen (Stichwort Fassade, \cite[700]{goll2018entwurfsprinzipien}).
Ein Zugriff aus Rust heraus soll somit stark vereinfacht werden.

In \autoref{draft:libshim} ist hierzu eine Detailansicht der Crate \textit{libshim-sys} dargestellt, inklusive C-Datenstrukturen und C++ Klassen.

\begin{figure}[H]
	\centering
	\includegraphics[width=2.5\textwidth]{dia/libshim}
	\caption{Detailansicht der Crate \textit{libshim-sys}}
	\label{draft:libshim}
\end{figure}

Die orange eingefärbten Klassen und Datenstrukturen aus \autoref{draft:libshim} stellen den nötigen Adaptercode dar.
Die in türkis eingefärbten Klassen und Schnittstellen sind die aus der C++ Implementation stammende Klassen und Schnittstellen, die nicht verändert werden dürfen.

Für das Laufzeitverhalten sind die zusätzlichen Funktionsaufrufe durch den Adaptercode (\textit{AlgorithmShim} zu \textit{RustShim}, \textit{RustShim} zu \textit{RustShimInternal} und \textit{RustShimInternal} zu \textit{UpdateQueue}, gut zu sehen an der enormen Breite von \autoref{seq_dia:algorithm:cpp:binding:communication}) als ungünstig eingestuft.
Die Komposition von \textit{AlgorithmShim} in \textit{ExternalAlgorithm} soll dem Compiler ermöglichen, den Funktionsaufruf von \textit{send\_sensor\_frame(frame: Box<SensorFrame>)} zu inlinen und so das Laufzeitverhalten zu verbessern.

In der \autoref{seq_dia:algorithm:cpp:binding:create} wird aufgezeigt, wie der C++ Algorithmus instantiiert wird.
\autoref{seq_dia:algorithm:cpp:binding:communication} zeigt wie eine \textit{SensorFrame}-Nachricht weitergeleitet und mit einer \textit{RawMessage} beantwortet wird.
Zur Vereinfachung sind hierzu einige Schritte, wie die Registrierung des Fahrzeugs, zwischen den Abbildungen ausgelassen.
Die Sequenzdiagramme sind mit den Hintergrundfarben aus den bisherigen Diagrammen eingefärbt, um eine Zuordnung der aufgezeigten Klassen zu vereinfachen.



\begin{landscape}
\vspace*{\fill}
\begin{figure}[H]
	\begin{tikzpicture}[scale=0.65, every node/.style={transform shape}]
	{[on background layer]
		\fill[green!15] (-13,1) -- (-7,1) -- (-7,-8.5) -- (-13,-8.5) -- cycle;
		\fill[red!30!white!15] (-7,1) -- (1,1) -- (1,-8.5) -- (-7,-8.5) -- cycle;
		\fill[orange!40!white!15] (1,1) -- (13,1) -- (13,-8.5) -- (1,-8.5) -- cycle;
		\fill[cyan!8] (13,1) -- (21,1) -- (21,-8.5) -- (13,-8.5) -- cycle;
	}
	\begin{umlseqdiag} 
	\umlobject[x=-10,no ddots]{MEC-View-Server}
	%\umlmulti[x=-16,no ddots,class=Vehicle]{v}
	\umlobject[x=15,no ddots]{AlgorithmFactory}
	
	\umlobject[x=-5,no ddots]{ExternalAlgorithm}
	\umlobject[x=-1,y=-0.5,no ddots]{AlgorithmShim}
	\umlobject[x=3,y=-1,no ddots]{RustShim}
	
	\begin{umlcall}[op=<<create>>,with return]{MEC-View-Server}{ExternalAlgorithm}
		\begin{umlcall}[op=<<create>>,with return]{ExternalAlgorithm}{AlgorithmShim}
			\begin{umlcall}[op=<<create>>,with return]{AlgorithmShim}{RustShim}
				\umlcreatecall[x=7,dt=5,class=RustShimInternal]{RustShim}{i}
				\umlcreatecall[x=11,dt=5,class=UpdateQueue]{RustShim}{q}
				\begin{umlcall}[op={<<static>> Create(e, q, config\_file)},return=a]{RustShim}{AlgorithmFactory}
					\umlcreatecall[x=19,class=Extension]{AlgorithmFactory}{e}
				\end{umlcall}
			\end{umlcall}
		\end{umlcall}
	\end{umlcall}
	
	\end{umlseqdiag} 
	\end{tikzpicture}
	\centering
	\caption{Instantiierung eines neuen C++ Algorithmus aus der Rust Implementation}
	\label{seq_dia:algorithm:cpp:binding:create}
\end{figure}
\begin{figure}[H]
	\begin{tikzpicture}[scale=0.65, every node/.style={transform shape}]
	{[on background layer]
		\fill[green!15] (-13,1) -- (-7,1) -- (-7,-8.5) -- (-13,-8.5) -- cycle;
		\fill[red!30!white!15] (-7,1) -- (1,1) -- (1,-8.5) -- (-7,-8.5) -- cycle;
		\fill[orange!40!white!15] (1,1) -- (13,1) -- (13,-8.5) -- (1,-8.5) -- cycle;
		\fill[cyan!8] (13,1) -- (21,1) -- (21,-8.5) -- (13,-8.5) -- cycle;
	}
	\begin{umlseqdiag} 
	
	\umlobject[x=-5,no ddots]{ExternalAlgorithm}
	\umlobject[x=-1,no ddots]{AlgorithmShim}
	\umlobject[x=3,no ddots]{RustShim}
	\umlobject[x=7,no ddots]{RustShimInternal}
	\umlobject[x=11,no ddots]{UpdateQueue}
	\umlobject[x=19,no ddots]{Extension}
	
	
	\umlmulti[x=-9,class=Sensor]{s}
	\begin{umlcall}[dt=5,op=SensorFrame, with return]{s}{ExternalAlgorithm}
		\begin{umlcall}[op=SensorFrame, with return]{ExternalAlgorithm}{AlgorithmShim}
			\begin{umlcall}[op=SensorFrame,with return]{AlgorithmShim}{UpdateQueue}
			\end{umlcall}
		\end{umlcall}
	\end{umlcall}
	
	
	\begin{umlcall}[dt=17,op=Pop(),return=SensorFrame]{Extension}{UpdateQueue}
	
	\end{umlcall}
	
	
	\umlmulti[x=-12,class=Vehicle]{v}
	\begin{umlcall}[op=RawMessage,with return]{Extension}{RustShimInternal}
		\begin{umlcall}[op=RawMessage,with return]{RustShimInternal}{RustShim}
			\begin{umlcall}[op=RawMessage,with return]{RustShim}{AlgorithmShim}
				\begin{umlcall}[op=RawMessage,with return]{AlgorithmShim}{ExternalAlgorithm}
					\begin{umlcall}[op=RawMessage,with return]{ExternalAlgorithm}{v}
					\end{umlcall}
				\end{umlcall}
			\end{umlcall}
		\end{umlcall}
	\end{umlcall}
	
	\end{umlseqdiag} 
	\end{tikzpicture}
	\centering
	\caption{Kommunikation mit dem C++ Algorithmus}
	\label{seq_dia:algorithm:cpp:binding:communication}
\end{figure}
\vspace*{\fill}
\end{landscape}

%\todo{?? updated usecases}

%\todo{binary vs source code}

\clearpage
\section{Startparameter}

Alle in \autoref{requirements} genannten optionalen Anforderungen für Startparameter sind erfolgreich umgesetzt worden.
Die Ausgabe in \autoref{help} zeigt alle möglichen Startparameter des Systems an.

\helpinclude
	{help}
	{Hilfsinformationen der Rust-Implementation mit allen möglichen Parametern}
	{sections/help.info}


In der folgenden Übersicht sind die Startparameter aus den Anforderungen, eine kurze Erklärung und ein Beispiel gelistet.

\newcommand{\proveReq}[3]{\textbf{Anforderung \reqNumberForLabel{#1}: \reqNameForLabel{#1}} \\ #2 \\ Beispiel: \monospaceinline{mecview_server #3}}

\begin{itemize}
	\item \proveReq{impl:arg:log}{
		Mit dem Startparameter \monospaceinline{-l <LEVEL>} (Kurzform) oder \monospaceinline{--log <LEVEL>} (Langform) kann einer der folgenden Level gesetzt werden: \monospaceinline{trace, debug, info, warn, err}.
	}{--log trace}
	
	\item \proveReq{impl:arg:interface}{
		Mit dem Startparameter \monospaceinline{-i <INTERFACE>} (Kurzform) oder \monospaceinline{--interface <INTERFACE>} (Langform) kann eine lokale Netzwerkadresse des Systems übergeben werden, auf der für eingehende TCP-Verbindungen gelauscht werden soll.
	}{-i 127.0.0.1}
	
	\item \proveReq{impl:arg:port}{
		Der Startparameter \monospaceinline{-p <NUMBER>} (Kurzform) und \monospaceinline{--port <NUMBER>} setzt den TCP-Port, den der Server verwendet, um auf neue Verbindungen zu lauschen.
	}{--port 4711}
	
	\item \proveReq{impl:arg:init_msg}{
		Mit dem Startparameter \monospaceinline{-v <PATH>} (Kurzform) oder \monospaceinline{--init-message <PATH>} (Langform) kann der Pfad zu einer in XML-Datei übergeben werden, aus der die zu verschickende \textit{InitMessage}-Nachricht geladen wird.
		}{--init-message scenario_5086.xml}
		
	\item \proveReq{impl:arg:env_frame}{
		Mit dem Startparameter \monospaceinline{-e <PATH>} (Kurzform) oder \monospaceinline{--environment-frame <PATH>} (Langform) kann der Pfad zu einer in XML-Datei übergeben werden, aus der die zu verschickende \textit{EnvironmentFrame}-Nachricht geladen wird.
	}{-e Kreuzung_2.xml}
	
	\item \proveReq{impl:arg:alg_json}{
		Der Startparameter \monospaceinline{-a <PATH>} (Kurzform) und \monospaceinline{--algorithm <PATH>} setzt den Pfad, der dem externen C++ Algorithmus bei der Initialisierung übergeben wird.
		Wenn der \enquote{Dummy}-Algorithmus verwendet wird, wird dieser Parameter ignoriert.
		}{-a latency_measurement.json}
\end{itemize}

\section{Resistenz gegenüber böswilligen oder defekten Clients}

Die Anforderungen \reqNumberForLabel{dos:sensor} \enquote{\reqNameForLabel{dos:sensor}} und \reqNumberForLabel{dos:car} \enquote{\reqNameForLabel{dos:car}} (siehe \autoref{req:dos:sensor}) beschreiben ein Szenario, bei dem sich im MEC-View-Server Nachrichten anstauen.
Bei einem zu großen Rückstau könnte der Arbeitsspeicher ausgehen und weitere Versuche, Speicher zu allokieren, würden fehlschlagen.
Das bedeutet, die Erreichbarkeit des MEC-View-Servers kann durch einen böswilligen oder defekten Client beeinflusst werden.
Um zu verhindern, dass sich zu viele Nachrichten anstauen, sind die Kanäle (siehe \autoref{impl:channels}) zwischen Client und Algorithmus in ihrer Größe limitiert.
Bei einem Versuch, diese Limitierung zu überschreiten, wird die Verbindung von dem betroffenem Client getrennt.
Durch diese Maßnahme kann die Erreichbarkeit des MEC-View-Servers gewahrt werden.

%\clearpage

%\section{...}

%\todo{bzgl coverage viele tests für encodieren / decodieren, server instanz nicht getestet weil nur mit tokio verdrahtet... schwierig zu testen}


%\todo{tdd schwierig weil viel integration mit framework / async, schnell wird daraus integrationstest(?, unerwünscht)}

%\todo{rust-clippy: https://github.com/rust-lang-nursery/rust-clippy}


%\section{Strategien für Performance}

%\todo{\enquote{bypass} via RawMessage for algorithm->many vehicles}


%\todo{diagramm: jede future ein eigenes "paket", queues dazwischen für kommunikation}

%\todo{catch panic? mention how in \autoref{rust:no_null}}

%\todo{SRP, impl Object separat from impl CommandProcessor for Object, testability?}


%\section{libmessages make unsafe libmessages-sys safe}
	
%\subsection{Vorgehen, bindgen tests, C/unsafe/wrapper -> nach sicher ->  architektur entwickeln}
	
%\section{Unerwartete Schwierigkeiten}
	
%	\todo{Trailing zeroes issue, commit a02496d + tagged, libmessages/src/asn.rs:17 bzw :31 bzw :32 Ok((result.encoded as usize + 7) / 8}
	
%	\todo{unterschiedlicher Heap libc / rust --> Rust Heap wird von Rust aufgeräumt, libc von libc... or deadlock}
	
%	\todo{jenkins clippy nightly often broken}
	
%	\todo{RawMessage<T> machts leben schwer}
	
%\subsection{Schwierigkeit: Heap nicht gleich Heap}

%\todo{deadlock im heap allokieren, rust heap muss von rust aufgeräumt werden, libc von libc, asn+c++-alg -> libc}


% \section{Valgrind: Race Conditions all over the place}

%\section{Mocks für TDD}
