
%\chapter{Hochperformante, serverbasierte Kommunikationsplattform}
\chapter{Systemrelevante Technologien}
\label{com_plattform}

Dieses Kapitel erläutert weitere relevante Themen, die zur Umsetzung der hochperformanten, serverbasierten Kommunikationsplattform wichtig sind.

\section{Echtzeitsysteme}
\label{real_time_systems}
Echtzeitsysteme zeichnen sich im allgemeinen dadurch aus, eine Aufgabe in einem zuvor vorgegebenen Zeitraum bearbeiten zu können.
Es existiert zu einer Aufgabe also immer eine Frist.
Bei der Bewertung der Korrektheit eines Systems wird die Fähigkeit, eine Frist einhalten zu können, auch bewertet \cite[2]{perf:buttazzo2006soft}.
Je nach Art des Echtzeitsystems wird diese Frist jedoch unterschiedlich gewichtet:

\begin{itemize}
	\item Bei einem harten Echtzeitsystem kann eine Überschreitung der Frist einen katastrophalen Ausgang haben.
	Selbst im schlimmsten Fall darf diese Frist nicht überschritten werden.
	Deswegen wird in einem harten Echtzeitsystem die maximale Reaktionszeit dem Zeitraum bis zur Frist gegenübergestellt \cite[75]{douglass2003real}.
	Ein Ergebnis nach Ablauf der Frist wird als nutzlos gewertet \cite[2]{perf:wang2017real}.
	
	Zum Beispiel könnte eine zu späte Auswertung von Beschleunigungsdaten in einem Flugzeug zu einer verzögerten und mittlerweile falschen Reaktion und daraufhin zu einem Absturz führen \cite[5]{perf:laplante2004real}.
	
	\item Bei einem weichen Echtzeitsystem resultiert die Überschreitung des vorgegebenen Zeitraums nicht in einer Katastrophe.
	Es wird die durchschnittliche Reaktionszeit dem Zeitraum bis zur Frist gegenübergestellt. Eine seltene und unter Last auftretende Überschreitung wird in Kauf genommen \cite[76]{douglass2003real}.
	Das System führt in so einem Fall weiterhin seine Aufgaben aus, die Performance wird daraufhin aber als unzureichend eingestuft.
%	Weiche Echtzeitsysteme können sogar überhaupt keine Frist haben, sondern die Aufgabe, die Antwortzeit so gering wie möglich zu gehalten \cite[4]{perf:buttazzo2006soft}.
\end{itemize}

\section{Mobile Edge Computing}

Mobile Edge Computing (\gls{mec}) bezeichnet Recheneinheiten, die eine Cloud-ähnliche Umgebung am Rande des Mobilfunknetzes schaffen \cite[4]{etsi:mec}.
Wenn in dieser Arbeit auf MEC Bezug genommen wird, sind damit explizit direkt an Funkmasten montierte Recheneinheiten gemeint.
Dadurch, dass die Recheneinheiten direkt an einen Funkmast angeschlossen sind, können sie Anfragen aus dem Abdeckungsbereich der Antenne deutlich schneller beantworten (Latenz kleiner 20ms) als Cloudlösungen (Latenz ca 100ms) \cite[2]{perf:mec:fraunhofer}.
Hierfür werden die Anfragen aus dem Mobilfunknetz direkt an die Recheneinheit weitergeleitet, anstatt über einen Provider eine Internetverbindung zu einer Cloudlösung aufzubauen.

Die Serverimplementierung des \gls{mec}-View Projekts wird in einer \gls{mec}-Recheneinheit ausgeführt, um die Sensordaten der Sensoren möglichst schnell an die Fahrzeuge des Abdeckungsbereichs des Funkmastes weiterleiten zu können.


\input{sections/asn}

	
\section{Test-Driven Development}
\label{tdd}

\begin{quotation}
	\textit{\enquote{Failure is progress.}}
	\cite[5]{tdd}
\end{quotation}
%\begin{quotation}
%	\textit{\enquote{Make it run, make it good.}}
%	\cite[24]{tdd}
%\end{quotation}

Bei der Test-getriebenen Entwicklung werden Tests in den Vordergrund gestellt.
Die Implementierung einer neuen Funktionalität wird durch neue Tests, welche die Anforderung repräsentieren, eingeleitet.
Erst nachdem ein Test erfolgreich feststellt, dass die geforderte Funktionalität noch nicht vorhanden ist, wird mit der Implementierung begonnen.
Eine schnelle Implementierung hat hierbei die höchste Priorität und erlaubt temporär auch eine limitierende, \enquote{stinkende} und naive Vorgehensweise \cite[7]{tdd}.
%Der neue Code, der den Test zufriedenstellt, darf hierbei kurzzeitig \enquote{stinken} \todo{cite} und Qualitätsstandards verletzten.
Direkt im Anschluss wird ein Refactoring\footnote{Verbesserung des Codes und der Struktur ohne Änderung der Funktionalität} durchgeführt, um die Qualitätsstandards wieder einzuhalten.
Diese drei Phasen werden \enquote{red/green/refactor} bezeichnet:

\begin{itemize}
	\item \textbf{red}: Ein neuer Test wird erstellt, dieser stellt erfolgreich die Abwesenheit der Funktionalität fest, eine rote Fehlermeldung ist zu sehen.
	\item \textbf{green}: Der Test wird durch neuen Code zufriedengestellt; eine positive Ausgabe bestätigt dies. Eine schnelle Implementierung wird hierbei temporär einer hochwertigen bevorzugt \cite[24]{tdd}, da ein erfolgreicher Test das Selbstvertrauen beim Refactoring stärkt und helfen würde, fehlerhafte Tests zu finden \cite[152]{tdd}.
	\item \textbf{refactor}: Der neue Code wird aufgeräumt und verbessert, um den Qualitätsstandards gerecht zu werden.
\end{itemize}

Die Testgröße und der daraus resultierende Umfang der neuen Funktionalität wird durch die Zuversichtlichkeit des Entwicklers gesteuert \cite[42]{tdd}.
Eine hohe Zuversicht führe zu größeren Tests, die etwas mehr Funktionalität auf einmal prüfen, während eine hohe Unsicherheit zu vielen kleinen Tests führen würden.
Daraus resultiert, dass gerade komplexe Algorithmen mit vielen Tests abgesichert sein sollten.
Bestehende Tests bilden ein Sicherheitsnetz, mit dem Fehler durch Änderungen detektiert werden können.

%\todo{manchmal stellt man beim erstellen des tests fest, dass die Anforderung blöd ist}
Test-getriebene Entwicklung verändert auch die Vorgehensweise bei der Implementation von Anforderungen. Anstatt zu fragen \enquote{Wie würde ich das implementieren?}, wird überlegt \enquote{Wie würde ich das testen?} \cite[39]{tdd}, womit auch implizit gefragt wird, wie die äußere Schnittstelle idealerweise aussehen sollen \cite[4]{tdd}.


%\todo{p.11, shift of practice in p.13, \enquote{Make it run, make it good} p.24, no changes unless enough motivation p.34, tests run -> not broken anything p.37, never interrupt an interruption p.41, TDD is a steering process, unsure -> smaller steps, sure -> bigger steps p.42, Test First can reduce stress p.127}

%\todo{mention stress reduction?}


\section{Funktionale Sicherheit}
\label{com:safety}

\enquote{Sicherheit} ist im Deutschen kein eindeutiger Begriff.
Sowohl \enquote{Sichersein vor Gefahr oder Schaden} (\textit{to be safe}), \enquote{Freisein von Fehlern oder Irrtümern} (\textit{to be confident}) oder \enquote{Schutz vor Gefahren, die von außen auf Systeme oder Personen einwirken} (\textit{security}) könnten mit \enquote{sicher sein} gemeint sein \cite[5-6]{safety}.
Deswegen ist es wichtig, den Begriff \enquote{funktionale Sicherheit} kurz zu ergründen.

Bei funktionaler Sicherheit (\textit{safety}) geht es um die Betriebssicherheit, eine \enquote{Freiheit von unvertretbaren Risiken} \cite[6]{safety}.
Unvertretbare Risiken sind in erster Linie Personenschäden, weswegen einheitliche Regularien in Normen wie der IEC 61508 bzw der DIN EN 61508 festgehalten sind.
Für den Automobilbereich wurde die Norm in der ISO 26262 angepasst, um u.a. eine Einzelabnahme eines jeden Fahrzeuges, durch eine Gesamtabnahme des Produktes zu ermöglichen \cite[14]{safety}.

Durch die Test-getriebene Entwicklung und der Verwendung von Rust und dessen Garantien (siehe \autoref{rust:guarantees}), sollen Fehler reduziert und eine möglichst sichere Implementierung geschaffen werden.
Eine Entwicklung nach ISO 26262 findet nicht statt, da dies zum Einen nicht durch das Forschungsprojekt gefordert ist und zum Anderen den Umfang dieser Bachelorarbeit überschreitet.

%\todo{such shiat argument, arguemnt: more rust -> f. safety}
%Obwohl funktionale Sicherheit für das Forschungsprojekt \gls{mec}-View eine nicht irrelevante Rolle Bedeutung hat, wird in dieser Bachelorarbeit keine Entwicklung nach ISO 26262 vorgenommen.
%Zum einen sollen die Garantien von Rust (siehe \autoref{rust:guarantees}) viele mögliche Fehlerquellen generell ausschließen, zum anderen soll durch die Test-getriebene Entwicklung (siehe \autoref{tdd}) die Fehlerwahrscheinlichkeit weiter reduziert werden.
%Zuletzt ist anzumerken, dass das System nicht für einen Endanwender konzipiert ist, sondern nur durch entsprechendes Fachpersonal betrieben und in Notfallsituationen eingegriffen wird.

	
%\section{Sensordaten?}
	
%\section{TCP?}
	
%\todo{Kommunikation als Socket, FiFo, Fehlerkorrektur, erneutes senden bei Fehlern, richtige Reiehenfolge...}


\section{Asynchrone Kommunikation und Datenströme}

\begin{quotation}
	\textit{\enquote{However, for high-performance servers, you'll need to use asynchronous input and output.}}
	\cite[454]{rust:orly_programming}
\end{quotation}

Eine typische synchrone Kommunikation ist ein Funktionsaufruf.
Zuerst werden die Parameter vorbereitet, dann die Funktion aufgerufen.
Der weitere Code der aufrufenden Funktion wird nicht ausgeführt, bis der Aufruf der aufgerufenden Funktion beendet wurde.

Auch für Datenströme, zum Beispiel bei TCP-Verbindungen, bieten Standardbibliotheken der entsprechenden Programmiersprachen oft eine synchrone Kommunikation an.
Hierbei beendet ein Funktionsaufruf für das Versenden oder Empfangen von Daten (bei TCP Bytes) erst, wenn die erwartete Anzahl an Elementen empfangen oder versendet wurde.

Für einen Client, der nur zu einem Server eine Verbindung aufbaut, ist diese Herangehensweise aufgrund der niedrigen Komplexität gut geeignet.
Für einen Server, der mit vielen Datenströmen gleichzeitig kommunizieren muss, ist diese Herangehensweise nicht geeignet.
Eine sequentieller Sendeaufruf würde die Latenz des Servers pro Client um einen von der Verbindungsgeschwindigkeit abhängigen Wert erhöhen.
Einen Sende- und Empfangsthread je Client würde das Problem der Latenz lösen, jedoch aufgrund des je Thread benötigten Stacks und zusätzlichen Verwaltungsaufwand den Ressourcenverbrauch des Servers drastisch erhöhen.

Eine asynchrone Kommunikation ermöglicht dagegen die Kommunikation mit vielen Datenströmen gleichzeitig, ohne die zuvor erwähnte Probleme zu provozieren.
Bei einem asynchronen Sende- oder Empfangsaufruf wird nicht auf dessen Fertigstellung gewartet, sondern in der darunterliegende Implementation wird die Anfrage notiert, sobald möglich abgearbeitet und der Aufrufende bei Fertigstellung informiert.
Das erlaubt dem Aufrufer dem nächsten Datenstrom Daten zuzusenden, ohne dass dies durch die Fertigstellung des ersten Aufrufs verzögert wird.
Eine asynchrone Kommunikation erhöht jedoch die Komplexität des Aufrufers (hier: des Servers), da nun zusätzlich der Status einer Sende- und Empfangsanfrage nachverfolgt werden muss.
Im Gegenzug wird die Verwaltung von vielen Datenströmen bzw. Verbindungen mit wenigen Threads ermöglicht.

%Auch ein Funktionsaufruf kann asynchron erfolgen.
%Der Aufrufer teilt dem Aufgerufenem dabei die Anfrage und deren Parameter mit, ohne auf die Fertigstellung zu warten.
%Stattdessen kontaktiert der Aufgerufene den ursprünglichen Aufrufer nachdem die Anfrage bearbeitet wurde.
%Ein solches System wird oft als \enquote{Aktorsystem} bezeichnet.

%
%\section{Stack und Heap Geschwindigkeit}
%
%\todo{.}
%Allokation von Speicher auf dem Stack und dem Heap unterscheiden sich in ihrer Geschwindigkeit und ihrer möglichen Verwendungsart.
%Eine Allokation auf dem Stack hat keine Laufzeitkosten, da sie zur Compilezeit ermittelt werden kann.
%Die Lebenszeit des allokierten Speichers ist aber durch die Lebenszeit der Funktion, in der der Speicher allokiert wurde, limitiert.
%Eine allokation auf dem Heap hat dagegen Laufzeitkosten, da dynamisch ein ausreichend großer und freier Speicherbereich gesucht werden muss.
%Ein Speicherbereich auf dem Heap ist in der Lebenszeit nicht eingeschränkt.
%
%Die Verwendung von kurzlebigen Datenstrukturen auf dem Stack anstatt auf dem Heap, kann eine performante Programmierung ermöglichen, birgt jedoch auch Gefahren.
%Wenn versucht wird, auf die Datenstruktur nach ihrer Lebenszeit zuzugreifen oder diese zu modifizieren, wird im besten Fall ein ungültiger Wert gelesen und im schlimmsten Fall \todo{der Stack überschrieben. Ein unvorhersehbares Verhalten kann die Folge sein.}
%
%Viele Programmiersprachen lassen sich in zwei Kategorien einteilen, die, bei denen das Speichermanagement soweit abstrahiert ist, dass eine 
%
%In vielen Programmiersprachen mit einer Laufzeitumgebung, wie C\# oder Java, ist diese Thematik der Allokation auf dem Stack oder Heap weitestgehend nicht vom Programmierer beeinflussbar.
%
%
%
%für performance abwägen,
%stack: kostenlos,
%heap: laufzeitkosten,
%nachträglich kopieren langsam weil kopieren,
%stack limitierend,
%stack in c++ gefährlich wenn pointer gespeichert wird,
%
%weil stack kostenlos, möglichst auf dem stack weil performanter
%
%Programmiersprachen wie java/c\# verstecken das
%
%C++ gefährlich
%
%\section{Continuous Integration}
%
%\todo{prüft regelmäßig ob eingescheckter code qualitätsansprüchen erfüllt bzw ob überhaupt funktionsfähig, metrik, nachvollziehbare builds}