
			
\chapter{Auswertung}

In diesem Kapitel wird die Implementation des MEC-View-Servers in Rust mit der Referenzimplementation in C++ verglichen.
Hierzu wird die Testumgebung aus dem C++ Projekt auch auf die Rust Implementation angewandt: Fahrzeuge und Sensoren werden simuliert und die Laufzeit für die Übermittlung von Nachrichten wird gemessen.

Im ersten Testszenario führt die Implementation in Rust einen in Rust geschriebenen \enquote{Dummy}-Algorithmus aus (siehe Anforderung \reqNumberForLabel{impl:algorithmus} in \autoref{req:impl:algorithmus}).
Im zweiten Schritt wird stattdessen der \enquote{Dummy}-Algorithmus geladen, den auch die C++ Implementation benutzt.



\section{Testumgebung}

Die Testumgebung wird auf einem Ubuntu 16.04.4 LTS Server mit zwei Intel Xeon CPUs (E5-2620 v4 @ 2.10GHz) ausgeführt.
Der CPU Governor wurde für alle Tests auf \enquote{performance} gestellt, um Schwankungen in der CPU Taktung durch Energiesparmaßnahmen -- und damit Verfälschungen der Testergebnisse -- zu unterbinden.
Eine derart überdimensionierte Hardware soll Unterschiede im Laufzeitverhalten besser aufzeigen, ohne der limitierende Faktor zu sein.

Für jede Kombination aus Sensoren, Fahrzeugen und Serverimplementierung werden 10 Tests durchgeführt.
Während jedem Test wird für jede empfangene Nachricht am Fahrzeug, die Latenz seit dem Versand am Sensor in eine Datei geschrieben.
Nach einem Testdurchlauf werden die Anzahl an Nachrichten gezählt und der Durchschnitt für die Latenzen gebildet.

Zu jedem Zeitpunkt wird maximal ein Test gleichzeitig auf dem System ausgeführt.

Um Latenzen durch das Netzwerk auszuschließen, werden auch die virtuellen Sensoren und Fahrzeuge auf dem gleichen Server wie die Serverimplementation ausgeführt und durch die Loopback-Netzwerkschnittstelle verbunden.
Ein kurzer Test ergab hierbei einen Durchsatz von ca 40Gbit/s (mittels \textit{iperf}) und eine Latenz von ca 24us (mittels \textit{ping}) auf der Loopback-Netzwerkschnittstelle.
Auswirkungen auf die Testergebnisse sind damit vernachlässigbar klein.

Alle Implementationen sind im Release-Modus compiliert und in der C++ Implementation ist das \enquote{RoadClearanceModule} abgeschaltet.

\section{Vorgehen}
\label{eval:howto}

Das Vorgehen ist für alle Tests gleich und ist bis auf den Start des Servers durch ein Bash-Skript automatisiert.
Lediglich die Anzahl an Fahrzeugen und Sensoren, die als Übergabeparameter an das Skript übergeben werden, variieren je Testdurchlauf (10 Tests).
Das Vorgehen eines Tests sieht folgendermaßen aus:

\begin{itemize}
	\item Server mit Log-Level \enquote{info} starten, um den Server nicht durch unnötige Log-Ausgaben zu bremsen.
	\item Skript starten.
	\item Skript startet die Sensoren als Hintergrundprozesse.
	\item Skript pausiert für 2 Sekunden, um genügend Zeit für den Verbindungsaufbau der Sensoren einzuräumen.
	\item Skript startet die Fahrzeuge, die 5 Sekunden nach dem Verbindungsaufbau das Umfeldmodell für 60 Sekunden abonnieren.
	\item Skript wartet auf Prozessende der Fahrzeuge.
	\item Skript beendet alle Sensoren.
	\item Skript pausiert für 2 Sekunden, um dem Server genügend Zeit für den Verbindungsabbau der Sensoren und Fahrzeuge einzuräumen.
	\item Skript wiederholt alle Schritt ab Schritt 2, bis 10 Durchläufe ausgeführt wurden.
\end{itemize}

Für jedes Umfeldmodell, das von einem Fahrzeug empfangen wird, wird auf der Konsole die Latenz in ganzen Millisekunden ausgegeben.
Diese Latenz wird anhand der Differenz zwischen dem Zeitstempel in der empfangenen Nachricht und der aktuellen Zeit errechnet.
Alle ausgegebenen Latenzen werden mittels \textit{Bash}-Pipe (und einem \textit{grep} und \textit{cut}) in eine Datei gespeichert.
Der Client wird hierbei nicht durch den Dateizugriff gebremst, da dies asynchron im letzten Prozess der \textit{Bash}-Pipe geschieht.
Bei der Auswertung wird der Durchschnitt errechnet (mittels \textit{awk}-Skript).

Für jeden Test werden 25 virtuelle Sensoren mit der Server-Instanz verbunden.
Jeder dieser Sensoren versendet in Intervallen von 100ms eine \textit{SensorFrame}-Nachricht.
Hieraus resultieren 250 Nachrichten pro Sekunde.
Die Anforderung \reqNumberForLabel{exec:time} (siehe \autoref{req:exec:time}) mit 200 Nachrichten pro Sekunde ($6*10 + 7*20$) ist somit übererfüllt.
Für jede empfangene \textit{SensorFrame}-Nachricht generiert der \enquote{Dummy}-Algorithmus eine \textit{EnvironmentFrame}-Nachricht und überträgt in diese den Zeitstempel aus der \textit{SensorFrame}-Nachricht.
Für jede Implementation werden 10 Tests mit 1 bis inklusive 5 Fahrzeugen durchgeführt.

Zum Testzeitpunkt ist eine \textit{SensorFrame}-Nachricht 517 Bytes groß und eine \textit{EnvironmentFrame}-Nachricht 2153 Bytes groß.
Dies stellt für den Server eine besondere Stresssituation dar.
Im Produktivbetrieb und mit dem Fusionsalgorithmus der Universität Ulm werden \textit{EnvironmentFrame}-Nachrichten nur alle 100ms an die Fahrzeuge versendet und nicht für jede empfangene \textit{SensorFrame}-Nachricht.
Es wird erwartet, \todo{dasss wenn} eine Serverimplementation mit dieser Stresssituation umgehen kann, sie auch die Anforderung \reqNumberForLabel{exec:time} im Produktivbetrieb erfüllen kann.

\section{Ergebnisse}
\label{eval:results}

In der \autoref{dia_25_60s} sind auf der linken Seite die Messergebnisse dargestellt, die durch das in \autoref{eval:howto} beschrieben Vorgehen gesammelt wurden.
Auf der rechten Seite ist für jede Implementation ein Boxplot für jeweils alle Latenzen aufgezeichnet.

\newcommand{\makeDias}[3]{
	\begin{figure}[H]
		\centering
		\begin{subfigure}{.65\textwidth}
			\centering
			\begin{tikzpicture}
			\begin{axis}[
				ymin=0, ymax=#2,
				xmin=0, xmax=#3,
				width=\textwidth, height=20em,
				xlabel={Anzahl der Nachrichten},
				ylabel={Durchschnittliche Latenz in ms},
				boxplot/draw direction=y,
				legend pos=north west,
			]
			
			\legend{Rust,,C++,,Rust mit C++ Alg.,}
			
			\draw[very thick,color=black!10] (0,5) -- (#3,5);
			
			\addplot gnuplot [raw gnuplot,id=rust#1,mark=none,very thick,color=brown!30]{
				set xrange [0:#3];
				f(x)=a*x+b;
				fit f(x) "data/rust_times_for_#1.dat" via a,b;
				plot f(x)};
			\addplot plot
			[only marks,mark=o,thick,color=brown] 
			file {data/rust_times_for_#1.dat};
			
			\addplot gnuplot [raw gnuplot,id=cpp#1,mark=none,very thick,color=blue!30]{
				set xrange [0:#3];
				f(x)=a*x+b;
				fit f(x) "data/cpp_times_for_#1.dat" via a,b;
				plot f(x)};
			\addplot plot
			[only marks,mark=x,thick,color=blue] 
			file {data/cpp_times_for_#1.dat};
			
			\addplot gnuplot [raw gnuplot,id=cpp#1,mark=none,very thick,color=red!30]{
				set xrange [0:#3];
				f(x)=a*x+b;
				fit f(x) "data/rust_cpp_alg_times_for_#1.dat" via a,b;
				plot f(x)};
			\addplot plot
			[only marks,mark=x,thick,color=red] 
			file {data/rust_cpp_alg_times_for_#1.dat};
			
			
			\end{axis}
			\end{tikzpicture}
			\caption{Latenz-Nachrichtenanzahl Diagramm}
			\label{#1} 
		\end{subfigure}%
		\begin{subfigure}{.35\textwidth}
			\centering
			\begin{tikzpicture}
			\begin{axis}[
			ymin=0, ymax=#2,
			boxplot/draw direction=y,
			xtick={1,2,3},
			xticklabels={Rust,C++,R++},
			width=\textwidth,
			height=20em
			]
			\addplot+[
			boxplot={average=auto},color=brown!80
			] table {data/rust_times_for_#1.dat}
			\printboxplotdata;
			
			\addplot+[
			boxplot={average=auto},color=blue!80
			] table {data/cpp_times_for_#1.dat}
			\printboxplotdata;
			
			\addplot+[
			boxplot={average=auto},color=red!80
			] table {data/rust_cpp_alg_times_for_#1.dat}
			\printboxplotdata;
			
			\end{axis}
			\end{tikzpicture}
			\caption{Boxplot für\\die Latenz}
			\label{#1_boxplot}
		\end{subfigure}
		\caption{Laufzeitverhalten der MEC-View-Server Implementationen}
		\label{dia_#1}
	\end{figure}
}

\makeDias{25_60s}{10.5}{90000}

\subsubsection{Beschreibung}

Die Y-Achse gibt die durchschnittliche Latenz in Millisekunden pro Nachricht und die X-Achse die Anzahl an Nachrichten für einen Test wieder.
Braune Kreise markieren einzelne Testergebnisse mit der Rust Implementation, blaue Kreuze mit der C++ Implementation und rote Kreuze mit der Rust Implementation und dem C++ Algorithmus.
Über alle Testergebnisse einer Implementation ist in der jeweiligen Farbe eine Trendlinie gelegt.
Zudem verläuft eine waagrechte Gerade auf Höhe von 5ms. Sie markiert die maximale Latenz bei zwei Fahrzeugen (ca 30.000 Nachrichten) aus Anforderung \reqNumberForLabel{exec:time} (siehe \autoref{req:exec:time}).

Es sind 5 Gruppierungen je Implementation auf der X-Achse zu erkennen (bei etwa 15.000, 30.000, 45.000, 60.000 und 75.000 Nachrichten).
Dies resultiert aus der unterschiedlichen Anzahl an Fahrzeugen und der deshalb multiplikativ wachsenden Gesamtanzahl an übermittelten Nachrichten.
Auf der Y-Achse ist dagegen für jede Gruppe eine Streuung zu sehen.
Während sich die Streuung bei der Rust Implementation mit zunehmenden Fahrzeugen eher verringert, steigt bei der C++ Implementation die Streuung deutlich.
Jede Gruppierung einer Implementation hat zudem die Tendenz, eine höhere durchschnittliche Latenz wie ihre vorgehende Gruppe aufzuweisen.
Dies ist durch die jeweilig steigende Trendlinie gut zu erkennen.

Die Rust und die C++ Implementierung weisen bei einem Client etwa die selbe durchschnittliche Latenz auf, während die Rust Implementation mit dem C++ Algorithmus hier eine leicht erhöhte Latenz aufweist.
Die Trendlinie der C++ Implementation verläuft bei steigender Anzahl an Nachrichten deutlich steiler wie die Trendlinie der anderen zwei Implementationen.
Bei zwei Fahrzeugen sind die beiden Rust Implementationen gleichauf und bei weiteren Fahrzeugen hat die Rust Implementation mit dem C++ Algorithmus eine geringere durchschnittliche Latenz wie die reine Rust oder die C++ Implementation.

\subsubsection{Auswertung}

Aus dem Diagramm ist zu erkennen, dass sowohl die C++ Implementation als auch die Rust Implementationen, trotz erhöhtem Stress, die Anforderung \reqNumberForLabel{exec:time} (siehe \autoref{req:exec:time}) erfüllen.
Im Gegensatz zur C++ Implementation erfüllen die Rust Implementationen dies auch noch bei mehr Fahrzeugen (getestet bis inklusive 5, die Trendlinie lässt aber noch mehr vermuten).

Der proportionale Anstieg der Reaktionszeit der C++ Implementation für jedes zusätzlich verbundene Fahrzeug (etwa 2ms bei einem Fahrzeug, kurz unter 4ms, 6ms, 8ms und 10ms bei 2, 3, 4 und 5 Fahrzeugen) lässt einen Fehler bei der Parallelisierung der Fahrzeuge vermuten.
Der Versand von Nachrichten an die verbundenen Fahrzeuge scheint nicht parallel, sondern sequenziell ausgeführt zu werden.
Vergleiche zwischen der Rust und C++ Implementierung für mehr als einem verbundenem Fahrzeug sind daher wenig aussagekräftig.

Interessant ist der Verlauf der roten Linie (Rust mit C++ Algorithmus) zur braunen Linie (Rust Algorithmus).
Eine Verschlechterung der Reaktionszeit, wie mit nur einem Fahrzeug (etwa 15.000 Nachrichten) gegenüber der reinen Rust Implementation war, durch die erhöhte Komplexität und die weitere Schicht zur Einbindung des C++ Algorithmus, zu erwarten gewesen.
Eine ähnliche Reaktionszeit bei 1, gleiche Reaktionszeit bei 2 Fahrzeugen und bessere Reaktionszeit ab 3 Fahrzeugen ist dagegen unerwartet gewesen.
Erst bei einer Codanalyse wurde klar, dass dies vermutlich daran liegt, dass der C++ Algorithmus parallel zum Rust Algorithmus-Adapter ausgeführt wird.
Die Encodierung der Antwort (\textit{EnvironmentFrame}-Nachricht nach \textit{RawMessage}, etwa 130\textmu s) wird daher asynchron zum Aufbereiten der nächsten und Weiterleiten der vorherigen Nachricht an die Fahrzeuge ausgeführt.

Dieses weitere asynchrone Verhalten setzt eines der für das \enquote{Channel Architektur Pattern} erwähnten Optimierungsmöglichkeiten um (siehe \autoref{design:communication:architecture}).
Wie in \cite[160]{douglass2003real} beschrieben, wird durch die parallele Verarbeitung von mehreren Elementen in einem Kanal (in diesem Fall der Kanal vom \textit{AlgorithmAdapter} über den C++ Algorithmus zu den Fahrzeugen) die Verarbeitung einer hohen Datenmenge ermöglicht.

Eine Implementation in Rust scheint keinen auffallenden oder gravierenden Nachteil im Laufzeitverhalten gegenüber einer Implementation in C++ aufzuweisen.
Das Szenario mit einem verbundenem Fahrzeug lässt dagegen vermuten, dass sich das Laufzeitverhalten der beiden Programmiersprachen sehr ähnelt.
Auch lässt der geringe Anstieg der Rust-Kurven wenig Spielraum, um von einer ausgebesserten C++ Implementation auffallend stark übertrumpft zu werden, da
kein oder ein negativer Anstieg der Kurve bei Erhöhung der Last aus logischen Gründen ausgeschlossen ist.

\subsubsection{Nachtrag}

Aufgrund der schwachen Aussagekräftigkeit des ersten Tests, wurde ein weiterer Test durchgeführt. Anstatt die Anzahl der Fahrzeuge zu variieren, wobei die C++ Implementation eine Schwäche zeigt, variiert die Anzahl der Sensoren, bei nur einem verbundenem Fahrzeug.
In der \autoref{sensors_60s} ist hierzu das Resultat für 25, 50, 75 und 100 Sensoren zu sehen.

\makeDias{sensors_60s}{12.5}{80000}

Zu sehen ist, dass die Rust-Implementationen trotzdem geringere Laufzeiten aufweisen.
Die C++ Implementation zeigt keinen proportionalen Anstieg, weshalb dem Vergleich diesmal eine höhere Aussagekräftigkeit zugesprochen werden kann.

%\section{..}
%\todo{Während den tests zeigte sich ein Fehler im C++ Server. Race-conditional missing cleanup for closed sockets in certain error cases?}