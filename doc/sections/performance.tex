
%\chapter{Hochperformante, serverbasierte Kommunikationsplattform}
\chapter{\todo{\enquote{Systemrelevant}?}}
\label{com_plattform}

Dieses Kapitel erläutert weitere, relevante Themen, die zur Umsetzung der hochperformante, serverbasierte Kommunikationsplattform wichtig sind.

\section{Echtzeitsysteme}
\label{real_time_systems}
Echtzeitsysteme zeichnen sich im allgemeinen dadurch aus, eine Aufgabe in einem zuvor vorgegebenen Zeitraum bearbeiten zu können.
Es existiert zu einer Aufgabe also immer eine Frist.
Bei der Bewertung der Korrektheit eines Systems wird die Fähigkeit, eine Frist einhalten zu können, auch bewertet \cite[2]{perf:buttazzo2006soft}.
Je nach Art des Echtzeitsystems, wird diese Frist jedoch unterschiedlich gewichtet:

\begin{itemize}
	\item Bei einem harten Echtzeitsystem kann eine Überschreitung der Frist einen katastrophalen Ausgang haben.
	Selbst im schlimmsten Fall darf diese Frist nicht überschritten werden.
	Deswegen wird in einem harten Echtzeitsystem die maximale Reaktionszeit dem Zeitraum bis zur Frist gegenübergestellt \cite[75]{douglass2003real}.
	Ein Ergebnis nach Ablauf der Frist wird als nutzlos gewertet \cite[2]{perf:wang2017real}.
	
	Zum Beispiel könnte eine zu späte Auswertung von Beschleunigungsdaten in einem Flugzeug zu einer verzögerten und mittlerweile falschen Reaktion und daraufhin zu einem Absturz führen \cite[5]{perf:laplante2004real}.
	
	\item Bei einem weichen Echtzeitsystem resultiert die Überschreitung des vorgegebenen Zeitraums nicht in einer Katastrophe.
	Es wird die durchschnittliche Reaktionszeit dem Zeitraum bis zur Frist gegenübergestellt, eine seltene und unter Last auftretende Überschreitung wird in Kauf genommen \cite[76]{douglass2003real}.
	Das System führt in so einem Fall weiterhin seine Aufgaben aus, die Performance wird aber \todo{abgewertet} eingestuft.
%	Weiche Echtzeitsysteme können sogar überhaupt keine Frist haben, sondern die Aufgabe, die Antwortzeit so gering wie möglich zu gehalten \cite[4]{perf:buttazzo2006soft}.
\end{itemize}

\section{Mobile Edge Computing}

\todo{refactor text}

Mobile Edge Computing (\gls{mec}) bezeichnet Recheneinheiten, die eine Cloud-ähnliche Umgebung am Rande des Mobilfunknetzes schaffen \cite[4]{etsi:mec}.
Wenn in dieser Arbeit auf MEC Bezug genommen wird, sind damit explizit direkt an Funkmasten montierte Recheneinheiten gemeint.
Dadurch, dass die Recheneinheiten direkt an eine Antenne angeschlossen sind, können sie Anfragen aus dem Abdeckungsbereich der Antenne deutlich schneller beantworten (Latenz kleiner 20ms) als Cloudlösungen (Latenz ca 100ms) \cite[2]{perf:mec:fraunhofer}.
Hierfür werden die Anfragen aus dem Mobilfunknetz direkt an die Recheneinheit weitergeleitet, anstatt über einen Provider eine Internetverbindung zu einer Cloudlösung aufzubauen.
In dem \gls{mec}-View Projekt wird eine \gls{vm} in einer \gls{mec} Recheneinheit ausgeführt und die Verbindungen zu den Sensoren und dem Fahrzeuge \todo{durchgeschleust}.


%\section{Architekturmuster? oder erst während der Implementation?}
%\subsection{Was ist dann ein hochperformantes System}
%\section{Serverbasierte Kommunikationsplattform: MEC}

		
\input{sections/asn}

	
\section{Test-Driven Development}
\label{tdd}

\begin{quotation}
	\textit{\enquote{Failure is progress.}}
	\cite[5]{tdd}
\end{quotation}
%\begin{quotation}
%	\textit{\enquote{Make it run, make it good.}}
%	\cite[24]{tdd}
%\end{quotation}

Bei der Test-getriebenen Entwicklung werden Tests in den Vordergrund gestellt.
Die Implementierung einer neuen Funktionalität wird durch neue Tests, welche die Anforderung repräsentieren, eingeleitet.
Erst nachdem ein Test erfolgreich feststellt, dass die geforderte Funktionalität noch nicht vorhanden ist, wird mit der Implementierung begonnen.
Eine schnelle Implementierung hat hierbei die höchste Priorität und erlaubt temporär auch eine limitierende, \enquote{stinkende}\todo{cite} und naive Vorgehensweise \cite[7]{tdd}.
%Der neue Code, der den Test zufriedenstellt, darf hierbei kurzzeitig \enquote{stinken} \todo{cite} und Qualitätsstandards verletzten.
Direkt im Anschluss wird ein Refactoring\footnote{Verbesserung des Codes und der Struktur ohne Änderung der Funktionalität} durchgeführt, um die Qualitätsstandards wieder einzuhalten.
Diese drei Phasen werden \enquote{red/green/refactor} bezeichnet:

\begin{itemize}
	\item \textbf{red}: Ein neuer Test wird erstellt, dieser stellt erfolgreich die Abwesenheit der Funktionalität fest, eine rote Fehlermeldung ist zu sehen.
	\item \textbf{green}: Der Test wird durch neuen Code zufriedengestellt; eine positive Ausgabe bestätigt dies. Eine schnelle Implementierung wird hierbei temporär einer hochwertigen bevorzugt \cite[24]{tdd}, da ein erfolgreicher Test das Selbstvertrauen beim Refactoring stärkt und helfen würde, fehlerhafte Tests zu finden \cite[152]{tdd}.
	\item \textbf{refactor}: Der neue Code wird aufgeräumt und verbessert, um den Qualitätsstandards gerecht zu werden. \todo{Ein andauernder Testdurchlauf versichert dabei keine Regression der Funktionalität.}
\end{itemize}

Die Testgröße und der daraus resultierende Umfang der neuen Funktionalität wird durch die Zuversichtlichkeit des Entwicklers gesteuert \cite[42]{tdd}.
Eine hohe Zuversicht führe zu größeren Tests, die etwas mehr Funktionalität auf einmal prüfen, während eine hohe Unsicherheit zu vielen kleinen Tests führen würden.
Daraus resultiert, dass gerade komplexe Algorithmen mit vielen Tests abgesichert sein sollten.
Bestehende Tests bilden ein Sicherheitsnetz, mit dem \todo{defekte} Änderungen umgehend detektiert werden können.

%\todo{manchmal stellt man beim erstellen des tests fest, dass die Anforderung blöd ist}
Test-getriebene Entwicklung verändert auch die Vorgehensweise bei der Implementation von Anforderungen. Anstatt zu fragen \enquote{Wie würde ich das implementieren?}, wird überlegt \enquote{Wie würde ich das testen?} \cite[39]{tdd}, womit auch implizit gefragt wird, wie die äußere Schnittstelle idealerweise aussehen sollen \cite[4]{tdd}.


%\todo{p.11, shift of practice in p.13, \enquote{Make it run, make it good} p.24, no changes unless enough motivation p.34, tests run -> not broken anything p.37, never interrupt an interruption p.41, TDD is a steering process, unsure -> smaller steps, sure -> bigger steps p.42, Test First can reduce stress p.127}

%\todo{mention stress reduction?}


\section{Funktionale Sicherheit}
\label{com:safety}

\enquote{Sicherheit} ist im Deutschen kein eindeutiger Begriff.
Sowohl \enquote{Sichersein vor Gefahr oder Schaden} (\textit{to be safe}), \enquote{Freisein von Fehlern oder Irrtümern} (\textit{to be confident}) oder \enquote{Schutz vor Gefahren, die von außen auf Systeme oder Personen einwirken} (\textit{security}) könnten mit \enquote{sicher sein} gemeint sein \cite[5-6]{safety}.
Deswegen ist es wichtig, den Begriff \enquote{funktionale Sicherheit} kurz zu ergründen.

Bei funktionaler Sicherheit (\textit{safety}) geht es um die Betriebssicherheit, eine \enquote{Freiheit von unvertretbaren Risiken} \cite[6]{safety}.
Unvertretbare Risiken sind in erster Linie Personenschäden, weswegen einheitliche Regularien in Normen wie der IEC 61508 bzw der DIN EN 61508 festgehalten sind.
Für den Automobilbereich wurde die Norm in der ISO 26262 angepasst, um u.a. eine Einzelabnahme eines jeden Fahrzeuges, durch eine Gesamtabnahme des Produktes zu ermöglichen \cite[14]{safety}.
\todo{Erwähnung?: Einstufung (A)SIL -> Gegenmaßnahmen}

Durch die Test-getriebene Entwicklung und der Verwendung von Rust und dessen Garantien (siehe \autoref{rust:guarantees}), sollen Fehler reduziert und eine möglichst sichere Implementierung geschaffen werden.
Eine Entwicklung nach ISO 26262 findet nicht statt, da dies zum Einen nicht durch das Forschungsprojekt gefordert ist und zum Anderen den Umfang dieser Bachelorarbeit überschreitet.

%\todo{such shiat argument, arguemnt: more rust -> f. safety}
%Obwohl funktionale Sicherheit für das Forschungsprojekt \gls{mec}-View eine nicht irrelevante Rolle Bedeutung hat, wird in dieser Bachelorarbeit keine Entwicklung nach ISO 26262 vorgenommen.
%Zum einen sollen die Garantien von Rust (siehe \autoref{rust:guarantees}) viele mögliche Fehlerquellen generell ausschließen, zum anderen soll durch die Test-getriebene Entwicklung (siehe \autoref{tdd}) die Fehlerwahrscheinlichkeit weiter reduziert werden.
%Zuletzt ist anzumerken, dass das System nicht für einen Endanwender konzipiert ist, sondern nur durch entsprechendes Fachpersonal betrieben und in Notfallsituationen eingegriffen wird.

	
%\section{Sensordaten?}
	
%\section{TCP?}
	
%\todo{Kommunikation als Socket, FiFo, Fehlerkorrektur, erneutes senden bei Fehlern, richtige Reiehenfolge...}


\section{Blockierende und nicht-blockierende Ein-/Ausgabe}

\begin{quotation}
	\textit{\enquote{However, for high-performance servers, you'll need to use asynchronous input and output.}}
	\cite[454]{rust:orly_programming}
\end{quotation}

\todo{.}

Bei einer blockierenden Ein-/Ausgabe wartet der aufrufende Thread darauf, das entweder die gewünschte Anzahl an Daten (oft Bytes) gelesen oder geschrieben wurden.
In vielen Situationen, wie zum Beispiel beim Lesen von einer einzelnen Datei oder beim Schreiben auf die Standardausgabe, kann ein blockierendes System die Anforderungen ausreichend erfüllen.
Für einen Server mit vielen Verbindungen kann dies aber zu einem sehr hohen Speicherverbrauch führen und die Leistungsfähigkeit reduzieren.

Bei einem blockierenden System müssen zu jeder Verbindung mehrere Threads gestartet werden, die ihre meiste Zeit damit verbringen, auf eingehende Daten zu warten oder um auf die Fertigstellung  von Schreiboperationen von ausgehenden Daten zu warten.
Da für jeden Thread ein Stack allokiert werden muss, ist in solch einem System ein hoher Speicherverbrauch je Verbindung gegeben.
In vielen Fällen wird zudem beim Aufruf einer blockierenden Methode der gesamte Prozess vom Scheduler des Betriebssystems pausiert und erst in der nächsten \todo{slice} fortgesetzt.
Dies reduziert die Leistungsfähigkeit des gesamten Prozesses.

Asynchrone Ein-/Ausgabe arbeitet nach anderen Prinzipien, es ist nicht nötig hierfür je Verbindung mehrere Threads zu erstellen.
Anstatt dass ein Thread auf eingehende Daten wartet, wird ein Callback registriert, der aufgerufen wird, sobald neue Daten eingetroffen sind.
Bei einem Schreibaufruf wird nicht gewartet, bis alle Daten versendet worden sind, sondern über einen Callback wird mitgeteilt, sobald alle Daten versendet worden sind.
Hierdurch können viele Verbindungen gleichzeitig und ressourcenschonend von wenigen Threads bearbeitet werden.

In Rust ist dies im Framework tokio durch Futures abstrahiert. Ein Funktionsaufruf zum Lesen von Bytes von einem \textit{TcpStream} gibt nicht die gelesenen Bytes zurück (blockierend), sondern eine \textit{Future} (dt. Zukunft), in der die Bytes gelesen sein werden (weiteres in \autoref{perf:future}). 

\todo{rust}

\todo{cites from tokio guide / doc}


\cite[303]{realtime}

Blocking heißt je thread ein stack, overhead für betriebssystem, viel nichts tun

\section{Nicht auf die Zukunft warten}
\label{perf:future}

\section{Stack / Heap performance}



für performance abwägen,
stack: kostenlos,
heap: laufzeitkosten,
nachträglich kopieren langsam weil kopieren,
stack limitierend,
stack in c++ gefährlich wenn pointer gespeichert wird,

weil stack kostenlos, möglichst auf dem stack weil performanter

Programmiersprachen wie java/c\# verstecken das

C++ gefährlich

\section{Continuous Integration}

\todo{prüft regelmäßig ob eingescheckter code qualitätsansprüchen erfüllt bzw ob überhaupt funktionsfähig, metrik, nachvollziehbare builds}